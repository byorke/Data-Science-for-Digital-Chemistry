{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c3ce6c",
   "metadata": {
    "papermill": {
     "duration": 0.020499,
     "end_time": "2023-03-26T00:20:55.918977",
     "exception": false,
     "start_time": "2023-03-26T00:20:55.898478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Geometric Operations and Other Image Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90465f",
   "metadata": {
    "papermill": {
     "duration": 0.01895,
     "end_time": "2023-03-26T00:20:56.031014",
     "exception": false,
     "start_time": "2023-03-26T00:20:56.012064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "In this part of the workshop, you will learn how to transform images using geometric transformations. This allows you to perform different operations to move, reshape and rotate an image. In the second part of the lab, you will learn how to implement a simple feature recognition algorithm. \n",
    "\n",
    "We will keep track of the changes you make using git and we will push the code to your own personal github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17531985",
   "metadata": {},
   "source": [
    "### Start tracking changes\n",
    "\n",
    "In the terminal (bottom panel), type:\n",
    "\n",
    "> git init\n",
    "\n",
    "This will create a hidden .git folder — Git will now track all your changes. Now you can define the branch of your repository that you will edit. \n",
    "\n",
    "> git branch -M main\n",
    "\n",
    "> git remote add \"your_name\" https://github.com/your-username/Digital-Skills.git\n",
    "\n",
    "> git remote remove origin\n",
    "\n",
    "And then re-add origin as above\n",
    "\n",
    "> git push -u \"your_name\" main\n",
    "\n",
    "Open the Source Control tab (icon on the left sidebar).\n",
    "\n",
    "You should see your committed files.\n",
    "\n",
    "Add your name to the top of this markdown cell and save the file.\n",
    "\n",
    "In the terminal:\n",
    "\n",
    "Stage the change\n",
    "\n",
    "> git add . \n",
    "\n",
    "Commit the change\n",
    "\n",
    "> git commit -m \"Describe what changed\"\n",
    "\n",
    "Push\n",
    "\n",
    "> git push\n",
    "\n",
    "You should now see the new code in your github repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c593921",
   "metadata": {},
   "source": [
    "Now we will look at using python for some image processing tasks.\n",
    "\n",
    "Import the packages you will need by running the cell below.\n",
    "\n",
    "You may need to install cv2 using the command *pip3 install opencv-python* in the terminal. \n",
    "\n",
    "*Open CV* is a computer vision library that is commonly used in scientific applications to manipulate, process and interpret images. It can also be used to support machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fb1b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:01.494652Z",
     "iopub.status.busy": "2023-03-26T00:21:01.494142Z",
     "iopub.status.idle": "2023-03-26T00:21:01.705906Z",
     "shell.execute_reply": "2023-03-26T00:21:01.704922Z"
    },
    "papermill": {
     "duration": 0.23718,
     "end_time": "2023-03-26T00:21:01.708910",
     "exception": false,
     "start_time": "2023-03-26T00:21:01.471730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589675e",
   "metadata": {
    "papermill": {
     "duration": 0.02109,
     "end_time": "2023-03-26T00:21:01.750103",
     "exception": false,
     "start_time": "2023-03-26T00:21:01.729013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below we define a helper function to plot two images side-by-side. You will not need to understand this code this moment, but this function will be used in this tutorial to showcase the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01b0ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:01.806930Z",
     "iopub.status.busy": "2023-03-26T00:21:01.805696Z",
     "iopub.status.idle": "2023-03-26T00:21:01.815466Z",
     "shell.execute_reply": "2023-03-26T00:21:01.813945Z"
    },
    "papermill": {
     "duration": 0.043111,
     "end_time": "2023-03-26T00:21:01.818213",
     "exception": false,
     "start_time": "2023-03-26T00:21:01.775102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_image(image_1, image_2,title_1=\"Orignal\",title_2=\"New Image\"):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_1,cmap=\"gray\")\n",
    "    plt.title(title_1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image_2,cmap=\"gray\")\n",
    "    plt.title(title_2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bcf63",
   "metadata": {
    "papermill": {
     "duration": 0.019385,
     "end_time": "2023-03-26T00:21:01.864017",
     "exception": false,
     "start_time": "2023-03-26T00:21:01.844632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Geometric Transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef01a5",
   "metadata": {
    "papermill": {
     "duration": 0.019847,
     "end_time": "2023-03-26T00:21:01.903832",
     "exception": false,
     "start_time": "2023-03-26T00:21:01.883985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " Geometric transformations allow you to perform different operations like translation i.e. to move, reshape and rotate an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80576c96",
   "metadata": {
    "papermill": {
     "duration": 0.025718,
     "end_time": "2023-03-26T00:21:01.957799",
     "exception": false,
     "start_time": "2023-03-26T00:21:01.932081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scaling \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d11f74",
   "metadata": {
    "papermill": {
     "duration": 0.020503,
     "end_time": "2023-03-26T00:21:01.998863",
     "exception": false,
     "start_time": "2023-03-26T00:21:01.978360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can resize an image using the function `resize()` from `cv2` module for this purpose.  You can specify the scaling factor or the size of the image:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5fa2a2",
   "metadata": {
    "papermill": {
     "duration": 0.023262,
     "end_time": "2023-03-26T00:21:02.044817",
     "exception": false,
     "start_time": "2023-03-26T00:21:02.021555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will now generate a simple toy image.\n",
    "\n",
    "Annotate the cell below with the following comments that describe what each line of code does (the comments are not in the correct order)\n",
    "- Fill a 4×4 square in the center of the toy_image with maximum brightness (white) for a pixel in an 8-bit grayscale  image. The 8-bit grayscale range is 0 = black → 255 = white.\n",
    "- Print a numerical array representating the image.\n",
    "- Create a toy_image that is 6×6 array filled with zeros — this is your blank (black) image.\n",
    "- Display the plot.\n",
    "- Plot the image in grayscale.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de1c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:02.092983Z",
     "iopub.status.busy": "2023-03-26T00:21:02.092415Z",
     "iopub.status.idle": "2023-03-26T00:21:02.374455Z",
     "shell.execute_reply": "2023-03-26T00:21:02.372967Z"
    },
    "papermill": {
     "duration": 0.307735,
     "end_time": "2023-03-26T00:21:02.377746",
     "exception": false,
     "start_time": "2023-03-26T00:21:02.070011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "toy_image = np.zeros((6,6))\n",
    "toy_image[1:5,1:5]=255\n",
    "toy_image[2:4,2:4]=0\n",
    "plt.imshow(toy_image,cmap='gray')\n",
    "plt.show()\n",
    "toy_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800f9e7",
   "metadata": {
    "papermill": {
     "duration": 0.019602,
     "end_time": "2023-03-26T00:21:02.420639",
     "exception": false,
     "start_time": "2023-03-26T00:21:02.401037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can rescale along a specific axis:\n",
    "\n",
    "- `fx`: scale factor along the horizontal axis  \n",
    "- `fy`: scale factor along the vertical axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261e7be",
   "metadata": {
    "papermill": {
     "duration": 0.019843,
     "end_time": "2023-03-26T00:21:02.460042",
     "exception": false,
     "start_time": "2023-03-26T00:21:02.440199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The interpolation setting decides how new pixel values are guessed when an image is resized.\n",
    "\n",
    "INTER_NEAREST uses the value of the closest pixel and may produce a 'blocky' image.\n",
    "\n",
    "INTER_CUBIC looks at several nearby pixels to make the image smoother.\n",
    "\n",
    "\n",
    "We will use INTER_NEAREST first since we are dealing with a simple image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c87da30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:02.502261Z",
     "iopub.status.busy": "2023-03-26T00:21:02.501847Z",
     "iopub.status.idle": "2023-03-26T00:21:02.694548Z",
     "shell.execute_reply": "2023-03-26T00:21:02.693111Z"
    },
    "papermill": {
     "duration": 0.217076,
     "end_time": "2023-03-26T00:21:02.697445",
     "exception": false,
     "start_time": "2023-03-26T00:21:02.480369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_toy = cv2.resize(toy_image,None,fx=2, fy=1, interpolation = cv2.INTER_NEAREST )\n",
    "plt.imshow(new_toy,cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af8ec1",
   "metadata": {},
   "source": [
    "In the cell below write a code snippet to scale the original toy image so that it is a 10 x 10 square and plot the scaled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48717a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_10by10 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687cf3dd",
   "metadata": {},
   "source": [
    "You can now commit this change to your github repository using the terminal:\n",
    "\n",
    "> git add .\n",
    "\n",
    "> git commit -m \"Describe what changed\"\n",
    "\n",
    "> git push\n",
    "\n",
    "Remember to do this when you add or change any code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74f2ec",
   "metadata": {
    "papermill": {
     "duration": 0.020702,
     "end_time": "2023-03-26T00:21:02.739512",
     "exception": false,
     "start_time": "2023-03-26T00:21:02.718810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Looking at real images\n",
    "\n",
    "Consider the following image:\n",
    "\n",
    "<img src=\"diffraction.png\" height=200>\n",
    "\n",
    "This is an X-ray diffraction image, to use these images to solve a 3D structure we need to process them and find the position and intensities of the reflections (or spots). The images are quite noisy which can cause problems when identifying the spot positions.\n",
    "\n",
    "We will use the computer vision package to process this image in different ways.\n",
    "\n",
    "First we will import it as 'image'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13bcf17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:02.784150Z",
     "iopub.status.busy": "2023-03-26T00:21:02.782761Z",
     "iopub.status.idle": "2023-03-26T00:21:03.135094Z",
     "shell.execute_reply": "2023-03-26T00:21:03.133857Z"
    },
    "papermill": {
     "duration": 0.38271,
     "end_time": "2023-03-26T00:21:03.142862",
     "exception": false,
     "start_time": "2023-03-26T00:21:02.760152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"diffraction.png\", cv2.IMREAD_GRAYSCALE) # We are importing this image as gray scale as we will use this later in the workshop.\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f2bfc",
   "metadata": {
    "papermill": {
     "duration": 0.033541,
     "end_time": "2023-03-26T00:21:04.292479",
     "exception": false,
     "start_time": "2023-03-26T00:21:04.258938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can scale the vertical axis by two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bb7ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:04.364524Z",
     "iopub.status.busy": "2023-03-26T00:21:04.364040Z",
     "iopub.status.idle": "2023-03-26T00:21:04.849781Z",
     "shell.execute_reply": "2023-03-26T00:21:04.848478Z"
    },
    "papermill": {
     "duration": 0.526468,
     "end_time": "2023-03-26T00:21:04.852944",
     "exception": false,
     "start_time": "2023-03-26T00:21:04.326476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_image = cv2.resize(image, None, fx=1, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "print(\"old image shape:\", image.shape, \"new image shape:\", new_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87841ea6",
   "metadata": {
    "papermill": {
     "duration": 0.040388,
     "end_time": "2023-03-26T00:21:04.934814",
     "exception": false,
     "start_time": "2023-03-26T00:21:04.894426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can also shrink the image by setting the scaling factor to a real number between 0 and 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d76b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:05.018729Z",
     "iopub.status.busy": "2023-03-26T00:21:05.017762Z",
     "iopub.status.idle": "2023-03-26T00:21:05.352963Z",
     "shell.execute_reply": "2023-03-26T00:21:05.350858Z"
    },
    "papermill": {
     "duration": 0.387181,
     "end_time": "2023-03-26T00:21:05.361726",
     "exception": false,
     "start_time": "2023-03-26T00:21:04.974545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_image = cv2.resize(image, None, fx=1, fy=0.5, interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "print(\"old image shape:\", image.shape, \"new image shape:\", new_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e6cf8",
   "metadata": {
    "papermill": {
     "duration": 0.054838,
     "end_time": "2023-03-26T00:21:05.473796",
     "exception": false,
     "start_time": "2023-03-26T00:21:05.418958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can  also specify the number of rows and columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493ac20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:05.566592Z",
     "iopub.status.busy": "2023-03-26T00:21:05.565108Z",
     "iopub.status.idle": "2023-03-26T00:21:05.570709Z",
     "shell.execute_reply": "2023-03-26T00:21:05.569670Z"
    },
    "papermill": {
     "duration": 0.055222,
     "end_time": "2023-03-26T00:21:05.573096",
     "exception": false,
     "start_time": "2023-03-26T00:21:05.517874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = 500\n",
    "cols = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730aef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:05.665976Z",
     "iopub.status.busy": "2023-03-26T00:21:05.664974Z",
     "iopub.status.idle": "2023-03-26T00:21:05.926035Z",
     "shell.execute_reply": "2023-03-26T00:21:05.924663Z"
    },
    "papermill": {
     "duration": 0.31199,
     "end_time": "2023-03-26T00:21:05.929896",
     "exception": false,
     "start_time": "2023-03-26T00:21:05.617906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_image = cv2.resize(image, (rows, cols), interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "print(\"old image shape:\", image.shape, \"new image shape:\", new_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf5a81",
   "metadata": {},
   "source": [
    "Now change the code above so that there are 500 rows and 500 columns, save the picture as 'diffraction_500.png' inside the current repository. You will notice it appears in the explorer menu on the left hand side of the screen.\n",
    "\n",
    "<img src=\"new_image.png\" height=200>\n",
    "\n",
    "You should commit after this change.\n",
    "\n",
    "You will need to use a slight different version of git add\n",
    "\n",
    "> git add -A\n",
    "\n",
    "This command adds all changes everywhere in the repo:\n",
    " \n",
    "- new files (including the image you have jused saved)\n",
    "\n",
    "- modified files\n",
    "\n",
    "- deleted files\n",
    "\n",
    "> git commit \"Describe what you have done\"\n",
    "\n",
    "> git push\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac5a04",
   "metadata": {
    "papermill": {
     "duration": 0.048749,
     "end_time": "2023-03-26T00:21:06.029922",
     "exception": false,
     "start_time": "2023-03-26T00:21:05.981173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Translation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d970bb9",
   "metadata": {
    "papermill": {
     "duration": 0.047925,
     "end_time": "2023-03-26T00:21:06.126425",
     "exception": false,
     "start_time": "2023-03-26T00:21:06.078500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Translation is  when you  shift the location of the image. <code>tx</code> is the number of pixels you shift the location in the horizontal direction and <code>ty</code> is the number of pixels you shift in the vertical direction. You can create the transformation matrix $M$ to shift the image. \n",
    "\n",
    "\n",
    "In this example, we shift an image 100 pixels horizontally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578ea47",
   "metadata": {},
   "source": [
    "<img src=\"molecule.png\" height=200>\n",
    "\n",
    "We can use different commands to change the oritentation of the image. \n",
    "\n",
    "In the code space below import 'molecule.png' as image2 using the cv2.imread command.\n",
    "\n",
    "To preserve the colours don't use the grayscale command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ca71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f827ed2b",
   "metadata": {},
   "source": [
    "Is it time to commit again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b598067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:06.236302Z",
     "iopub.status.busy": "2023-03-26T00:21:06.235799Z",
     "iopub.status.idle": "2023-03-26T00:21:06.244816Z",
     "shell.execute_reply": "2023-03-26T00:21:06.243463Z"
    },
    "papermill": {
     "duration": 0.066786,
     "end_time": "2023-03-26T00:21:06.247122",
     "exception": false,
     "start_time": "2023-03-26T00:21:06.180336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tx = 100\n",
    "ty = 0\n",
    "M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24900b3a",
   "metadata": {
    "papermill": {
     "duration": 0.047389,
     "end_time": "2023-03-26T00:21:06.341502",
     "exception": false,
     "start_time": "2023-03-26T00:21:06.294113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The shape of the image is given by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38482d7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:06.439029Z",
     "iopub.status.busy": "2023-03-26T00:21:06.438510Z",
     "iopub.status.idle": "2023-03-26T00:21:06.444568Z",
     "shell.execute_reply": "2023-03-26T00:21:06.443265Z"
    },
    "papermill": {
     "duration": 0.058292,
     "end_time": "2023-03-26T00:21:06.447011",
     "exception": false,
     "start_time": "2023-03-26T00:21:06.388719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows, cols, _ = image2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fcb21",
   "metadata": {
    "papermill": {
     "duration": 0.047749,
     "end_time": "2023-03-26T00:21:06.541217",
     "exception": false,
     "start_time": "2023-03-26T00:21:06.493468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We use the function <code>warpAffine</code> from the <code>cv2</code> module. The first input parater is an image array, the second input parameter is the transformation matrix <code>M</code>, and the final input paramter is the length and width of the output image $(cols,rows)$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358abd35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:06.639809Z",
     "iopub.status.busy": "2023-03-26T00:21:06.639282Z",
     "iopub.status.idle": "2023-03-26T00:21:06.652807Z",
     "shell.execute_reply": "2023-03-26T00:21:06.651734Z"
    },
    "papermill": {
     "duration": 0.066408,
     "end_time": "2023-03-26T00:21:06.655488",
     "exception": false,
     "start_time": "2023-03-26T00:21:06.589080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "new_image = cv2.warpAffine(image2, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e08f3",
   "metadata": {
    "papermill": {
     "duration": 0.050163,
     "end_time": "2023-03-26T00:21:06.760650",
     "exception": false,
     "start_time": "2023-03-26T00:21:06.710487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can plot the image; the portions of the image that do not have any intensities are set to zero:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110b37f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:06.864015Z",
     "iopub.status.busy": "2023-03-26T00:21:06.863217Z",
     "iopub.status.idle": "2023-03-26T00:21:07.196915Z",
     "shell.execute_reply": "2023-03-26T00:21:07.195585Z"
    },
    "papermill": {
     "duration": 0.3903,
     "end_time": "2023-03-26T00:21:07.201416",
     "exception": false,
     "start_time": "2023-03-26T00:21:06.811116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c492b",
   "metadata": {
    "papermill": {
     "duration": 0.055669,
     "end_time": "2023-03-26T00:21:07.316042",
     "exception": false,
     "start_time": "2023-03-26T00:21:07.260373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see some of the original image has been cut off. We can fix this by changing the output image size: <code>(cols + tx,rows + ty)</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce6a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:07.430976Z",
     "iopub.status.busy": "2023-03-26T00:21:07.430541Z",
     "iopub.status.idle": "2023-03-26T00:21:07.806561Z",
     "shell.execute_reply": "2023-03-26T00:21:07.805154Z"
    },
    "papermill": {
     "duration": 0.441011,
     "end_time": "2023-03-26T00:21:07.812967",
     "exception": false,
     "start_time": "2023-03-26T00:21:07.371956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_image = cv2.warpAffine(image2, M, (cols + tx, rows + ty))\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fb00c",
   "metadata": {
    "papermill": {
     "duration": 0.057596,
     "end_time": "2023-03-26T00:21:07.934257",
     "exception": false,
     "start_time": "2023-03-26T00:21:07.876661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "We can shift the image horizontally:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20e626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:08.053520Z",
     "iopub.status.busy": "2023-03-26T00:21:08.053051Z",
     "iopub.status.idle": "2023-03-26T00:21:08.411650Z",
     "shell.execute_reply": "2023-03-26T00:21:08.409942Z"
    },
    "papermill": {
     "duration": 0.424928,
     "end_time": "2023-03-26T00:21:08.416668",
     "exception": false,
     "start_time": "2023-03-26T00:21:07.991740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tx = 0\n",
    "ty = 50\n",
    "M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "new_iamge = cv2.warpAffine(image2, M, (cols + tx, rows + ty))\n",
    "plt.imshow(cv2.cvtColor(new_iamge, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac51c0",
   "metadata": {
    "papermill": {
     "duration": 0.062015,
     "end_time": "2023-03-26T00:21:08.545312",
     "exception": false,
     "start_time": "2023-03-26T00:21:08.483297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rotation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82f55f6",
   "metadata": {
    "papermill": {
     "duration": 0.063928,
     "end_time": "2023-03-26T00:21:08.671173",
     "exception": false,
     "start_time": "2023-03-26T00:21:08.607245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can rotate an image by angle θ which is achieved by the Rotation Matrix <code>getRotationMatrix2D</code>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a0d80",
   "metadata": {
    "papermill": {
     "duration": 0.062826,
     "end_time": "2023-03-26T00:21:08.796876",
     "exception": false,
     "start_time": "2023-03-26T00:21:08.734050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p><code>center</code>: Center of the rotation in the source image. We will only use the center of the image.</p>\n",
    "<p><code>angle</code>: Rotation angle in degrees. Positive values mean counter-clockwise rotation (the coordinate origin is assumed to be the top-left corner).</p>\n",
    "<p><code>scale</code>: Isotropic scale factor, in this course the value will be one.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d21265",
   "metadata": {
    "papermill": {
     "duration": 0.061049,
     "end_time": "2023-03-26T00:21:08.920792",
     "exception": false,
     "start_time": "2023-03-26T00:21:08.859743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can rotate our toy image by 45 degrees:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825e9de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:09.051649Z",
     "iopub.status.busy": "2023-03-26T00:21:09.051087Z",
     "iopub.status.idle": "2023-03-26T00:21:09.058886Z",
     "shell.execute_reply": "2023-03-26T00:21:09.057459Z"
    },
    "papermill": {
     "duration": 0.07885,
     "end_time": "2023-03-26T00:21:09.061504",
     "exception": false,
     "start_time": "2023-03-26T00:21:08.982654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta = 45.0\n",
    "M = cv2.getRotationMatrix2D(center=(3, 3), angle=theta, scale=1)\n",
    "new_toy_image = cv2.warpAffine(toy_image, M, (6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fcc9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:09.187660Z",
     "iopub.status.busy": "2023-03-26T00:21:09.187083Z",
     "iopub.status.idle": "2023-03-26T00:21:09.530328Z",
     "shell.execute_reply": "2023-03-26T00:21:09.528967Z"
    },
    "papermill": {
     "duration": 0.410341,
     "end_time": "2023-03-26T00:21:09.533142",
     "exception": false,
     "start_time": "2023-03-26T00:21:09.122801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_image(toy_image, new_toy_image, title_1=\"Orignal\", title_2=\"rotated image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182ab74",
   "metadata": {
    "papermill": {
     "duration": 0.066541,
     "end_time": "2023-03-26T00:21:09.665559",
     "exception": false,
     "start_time": "2023-03-26T00:21:09.599018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Looking at intensity values, we see that many values have been interpolated:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c45e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:09.800975Z",
     "iopub.status.busy": "2023-03-26T00:21:09.800514Z",
     "iopub.status.idle": "2023-03-26T00:21:09.807960Z",
     "shell.execute_reply": "2023-03-26T00:21:09.807027Z"
    },
    "papermill": {
     "duration": 0.078051,
     "end_time": "2023-03-26T00:21:09.810221",
     "exception": false,
     "start_time": "2023-03-26T00:21:09.732170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_toy_image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f1262e",
   "metadata": {
    "papermill": {
     "duration": 0.066976,
     "end_time": "2023-03-26T00:21:09.942293",
     "exception": false,
     "start_time": "2023-03-26T00:21:09.875317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can perform the same operation on color images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27097aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:10.091773Z",
     "iopub.status.busy": "2023-03-26T00:21:10.090929Z",
     "iopub.status.idle": "2023-03-26T00:21:10.096003Z",
     "shell.execute_reply": "2023-03-26T00:21:10.094995Z"
    },
    "papermill": {
     "duration": 0.081813,
     "end_time": "2023-03-26T00:21:10.098478",
     "exception": false,
     "start_time": "2023-03-26T00:21:10.016665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols, rows, _ = image2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa767f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:10.233034Z",
     "iopub.status.busy": "2023-03-26T00:21:10.232296Z",
     "iopub.status.idle": "2023-03-26T00:21:10.240095Z",
     "shell.execute_reply": "2023-03-26T00:21:10.238739Z"
    },
    "papermill": {
     "duration": 0.080403,
     "end_time": "2023-03-26T00:21:10.243159",
     "exception": false,
     "start_time": "2023-03-26T00:21:10.162756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = cv2.getRotationMatrix2D(center=(cols // 2 - 1, rows // 2 - 1), angle=theta, scale=1)\n",
    "new_image = cv2.warpAffine(image2, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69ca94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:10.378041Z",
     "iopub.status.busy": "2023-03-26T00:21:10.377297Z",
     "iopub.status.idle": "2023-03-26T00:21:10.717150Z",
     "shell.execute_reply": "2023-03-26T00:21:10.716029Z"
    },
    "papermill": {
     "duration": 0.41618,
     "end_time": "2023-03-26T00:21:10.723343",
     "exception": false,
     "start_time": "2023-03-26T00:21:10.307163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebadfc2",
   "metadata": {
    "papermill": {
     "duration": 0.069814,
     "end_time": "2023-03-26T00:21:10.868609",
     "exception": false,
     "start_time": "2023-03-26T00:21:10.798795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Mathematical Operations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40418bd",
   "metadata": {
    "papermill": {
     "duration": 0.070964,
     "end_time": "2023-03-26T00:21:11.008596",
     "exception": false,
     "start_time": "2023-03-26T00:21:10.937632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Array Operations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc987f",
   "metadata": {
    "papermill": {
     "duration": 0.06947,
     "end_time": "2023-03-26T00:21:11.148072",
     "exception": false,
     "start_time": "2023-03-26T00:21:11.078602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can perform array operations on an image; Using Python broadcasting, we can add a constant to each pixel's intensity value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ab87c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:11.295081Z",
     "iopub.status.busy": "2023-03-26T00:21:11.293103Z",
     "iopub.status.idle": "2023-03-26T00:21:11.666582Z",
     "shell.execute_reply": "2023-03-26T00:21:11.665030Z"
    },
    "papermill": {
     "duration": 0.453202,
     "end_time": "2023-03-26T00:21:11.673337",
     "exception": false,
     "start_time": "2023-03-26T00:21:11.220135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " new_image = image2 + 20\n",
    "\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79c2f2",
   "metadata": {
    "papermill": {
     "duration": 0.076052,
     "end_time": "2023-03-26T00:21:11.832653",
     "exception": false,
     "start_time": "2023-03-26T00:21:11.756601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can also multiply every pixel's intensity value by a constant value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1eb76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:11.990774Z",
     "iopub.status.busy": "2023-03-26T00:21:11.990220Z",
     "iopub.status.idle": "2023-03-26T00:21:12.308652Z",
     "shell.execute_reply": "2023-03-26T00:21:12.306870Z"
    },
    "papermill": {
     "duration": 0.408222,
     "end_time": "2023-03-26T00:21:12.317407",
     "exception": false,
     "start_time": "2023-03-26T00:21:11.909185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_image = 10 * image2\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf685ab",
   "metadata": {
    "papermill": {
     "duration": 0.082257,
     "end_time": "2023-03-26T00:21:12.492136",
     "exception": false,
     "start_time": "2023-03-26T00:21:12.409879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can add the elements of two arrays of equal shape. In this example, we generate an array of random noise with the same shape and data type as our image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21558121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:12.657738Z",
     "iopub.status.busy": "2023-03-26T00:21:12.656733Z",
     "iopub.status.idle": "2023-03-26T00:21:12.696977Z",
     "shell.execute_reply": "2023-03-26T00:21:12.695658Z"
    },
    "papermill": {
     "duration": 0.127022,
     "end_time": "2023-03-26T00:21:12.699716",
     "exception": false,
     "start_time": "2023-03-26T00:21:12.572694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Noise = np.random.normal(0, 10, (rows, cols, 3)).astype(np.uint8)\n",
    "Noise.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ed41b",
   "metadata": {
    "papermill": {
     "duration": 0.084039,
     "end_time": "2023-03-26T00:21:12.866023",
     "exception": false,
     "start_time": "2023-03-26T00:21:12.781984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We add the generated noise to the image and plot the result. We see the values that have corrupted the image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe9b0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:21:13.041008Z",
     "iopub.status.busy": "2023-03-26T00:21:13.040536Z",
     "iopub.status.idle": "2023-03-26T00:21:13.349467Z",
     "shell.execute_reply": "2023-03-26T00:21:13.348003Z"
    },
    "papermill": {
     "duration": 0.403867,
     "end_time": "2023-03-26T00:21:13.354947",
     "exception": false,
     "start_time": "2023-03-26T00:21:12.951080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_image = image2 + Noise\n",
    "\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2359c184",
   "metadata": {},
   "source": [
    "## False colouring\n",
    "\n",
    "Sometimes, it’s useful to change how an image is displayed — for example, to highlight contrast or to make features easier to see. In scientific imaging, this is often called false colouring or applying a colour map.\n",
    "\n",
    "To enhance visual contrast, we can apply a false colour map.\n",
    "OpenCV has many built-in options such as COLORMAP_JET, COLORMAP_HOT, and COLORMAP_TURBO.\n",
    "\n",
    "This maps pixel intensity values (dark → bright) to a colour gradient — for instance, blue for low values and red/yellow for high ones.\n",
    "It’s especially helpful for displaying diffraction patterns or other intensity-based data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colored = cv2.applyColorMap(image, cv2.COLORMAP_JET)\n",
    "plt.imshow(cv2.cvtColor(colored, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Colormapped Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9ad62",
   "metadata": {},
   "source": [
    "You can also change the overall tone of the image by adjusting individual colour channels.\n",
    "For example, adding more red can create a warm appearance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "tinted = color_img.copy()\n",
    "tinted[:, :, 2] = cv2.add(tinted[:, :, 2], 80)  # boost red channel\n",
    "plt.imshow(cv2.cvtColor(tinted, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Red-Tinted Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78ba9c",
   "metadata": {},
   "source": [
    "Try changing which channel you boost (0=blue, 1=green, 2=red) to see how it affects the result.\n",
    "\n",
    "In the cell below try to re-colour molecule.png (image2) using either a filter or boosting a colour channel and save the output.\n",
    "\n",
    "You can find a full list of filters here:\n",
    "\n",
    "https://docs.opencv.org/4.x/d3/d50/group__imgproc__colormap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19f96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406bd161",
   "metadata": {},
   "source": [
    "## Python image processing and feature recognition\n",
    "\n",
    "We can use python to remove noise from images, this can be useful when trying to interpret data. Let's look at the diffraction pattern again.\n",
    "\n",
    "The non-local means denoising (cv2.fastNlMeansDenoising) function removes noise whilst preserving edges in an image. \n",
    "\n",
    "Try changing the parameters to see how they affect the result:\n",
    "\n",
    "- h: strength of luminance filter (higher = more smoothing)\n",
    "\n",
    "- templateWindowSize: size of pixel neighborhood used to compare\n",
    "\n",
    "- searchWindowSize: size of window to search for similar blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51408f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.fastNlMeansDenoising(image, None, h=15, templateWindowSize=7, searchWindowSize=21)\n",
    "plt.subplot(121),plt.imshow(image)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.subplot(122),plt.imshow(dst)\n",
    "plt.imshow(dst, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d086a8",
   "metadata": {},
   "source": [
    "To process X-ray diffraction images we need to identify the position of each reflection (or spot) in the image. We can use computer vision tools to help identify the diffraction spots.\n",
    "\n",
    "First we will convert the image to a binary representation where the dark spots are black and the lighter grey parts are white.\n",
    "\n",
    "You may want to go back and change the dst filter strength so that only strong diffraction peaks are identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh = cv2.threshold(dst, 127, 255, cv2.THRESH_BINARY)\n",
    "plot_image(image, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3566087",
   "metadata": {},
   "source": [
    "Next we will use the *Hough Circle Transform*  to detect the spots. This alogirthm works by transforming points from the image space into a parameter space that represents potential circles. Each edge pixel \"votes\" for all possible circles that could pass through it, and peaks in this voting space correspond to likely circles in the original image.\n",
    "\n",
    "The key parameters to tune are:\n",
    "\n",
    "dp: The inverse ratio of the accumulator resolution — controls detection precision.\n",
    "\n",
    "minDist: The minimum distance between detected circle centers — avoids multiple detections of the same feature.\n",
    "\n",
    "param1: The higher threshold for edge detection (Canny filter).\n",
    "\n",
    "param2: The threshold for circle detection — lower values make detection more sensitive but may increase false positives.\n",
    "\n",
    "minRadius, maxRadius: The size range of circles to detect.\n",
    "\n",
    "By experimenting with these parameters, you can accurately isolate circular structures even in noisy or complex datasets, making this method a powerful tool for image analysis in physics and materials science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec072264",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_circles = cv2.HoughCircles(thresh, cv2.HOUGH_GRADIENT, dp=20, minDist=5, param1=10, param2=20, minRadius=4, maxRadius=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "if black_circles is not None:\n",
    "    black_circles = np.uint16(np.around(black_circles))\n",
    "    for i in black_circles[0, :]:\n",
    "        radius = i[2]\n",
    "        center = (i[0], i[1])\n",
    "        adjusted_radius = max(radius - (radius-2), 15)\n",
    "        cv2.circle(output, (i[0], i[1]), 2, (0, 0, 250), 5)    # draw center point\n",
    "        cv2.circle(output, center, adjusted_radius, (0, 255, 0), 1)\n",
    "\n",
    "plt.imshow(output)\n",
    "plt.title('Detected Circles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1a2e8",
   "metadata": {},
   "source": [
    "Change the parameters until you find the optimal peak finding settings so that strong peaks are identified and noise is not included. \n",
    "\n",
    "Save the Detected Circles image.\n",
    "\n",
    "In the cell below complete the code to print the number of peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_peaks = black_circles.shape[1]  # number of circles detected\n",
    "print(num_peaks)  #edit this line\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed100f",
   "metadata": {},
   "source": [
    "And now we will create a data frame containing the peak co-ordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a55a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_coords = []\n",
    "for i in black_circles[0, :]:\n",
    "    x, y, radius = i[0], i[1], i[2]\n",
    "    peak_coords.append((x, y))  # only centers\n",
    "\n",
    "df = pd.DataFrame(peak_coords, columns=['x', 'y']) #create a pandas data frame with the coordinates of each spot.\n",
    "print(df.head()) #print a few lines of the data frame to check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0340633",
   "metadata": {},
   "source": [
    "Let's find the intensity (pixel values) for each peak and add them to the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e275d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensities = [image[int(y), int(x)] for (x, y) in peak_coords]\n",
    "\n",
    "df['intensity'] = intensities\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13cdc8",
   "metadata": {},
   "source": [
    "Now we can export a column separated values (.csv) file containing the peak positions and intensitiy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('detected_peaks.csv', index=False)\n",
    "print(\"\\nPeak coordinates saved to 'detected_peaks.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b629e",
   "metadata": {},
   "source": [
    "Finally we will commit the final version of your code.\n",
    "\n",
    "Since we have made a number of changes to the settings and saved some new files we will create a new •branch•. \n",
    "\n",
    "Branches allow you to develop features, fix bugs, or safely experiment with new ideas in a contained area of your repository.\n",
    "\n",
    "To make a new branch you can type \n",
    "\n",
    "> git checkout -b test_branch\n",
    "\n",
    "then\n",
    "\n",
    "> git add .\n",
    "\n",
    "> git commit -m \"Describe what changed\"\n",
    "\n",
    "> git push origin test_branch\n",
    "\n",
    "Check your github repository and make sure everything has been pushed properly.\n",
    "\n",
    "You'll notice you now have two branches. \n",
    "\n",
    "You should now see the following:\n",
    "\n",
    "<img src =\"pull_request.png\">\n",
    "\n",
    "Click on compare & pull request. You should be able to see the differences between the two branches.\n",
    "\n",
    "To merge them, create a pull request and then merge the pull request.\n",
    "\n",
    "You can now delete the test branch. All of the changes should be visible in the main branch.\n",
    "\n",
    "You may now add a short description of the code and edit the ReadMe file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.084756,
   "end_time": "2023-03-26T00:21:37.829536",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-26T00:20:44.744780",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
